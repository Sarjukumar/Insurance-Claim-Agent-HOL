{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000002",
   "metadata": {
    "name": "cell3"
   },
   "source": [
    "## 0. Load Test Data\n",
    "\n",
    "In this section you will:\n",
    "- Load structured test data in Core Claims related tables.\n",
    "\n",
    "Run each SQL cell once in order. In Snowflake Notebooks, use a SQL cell type;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "USE DATABASE INSURANCE_CLAIMS_DEMO;\n",
    "USE SCHEMA LOSS_CLAIMS;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000004",
   "metadata": {
    "language": "sql",
    "name": "cell5",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- Seed the tables with multiple sample property and auto claims\n",
    "INSERT INTO CLAIMS (\n",
    "    CLAIM_NO, LINE_OF_BUSINESS, CLAIM_STATUS, CAUSE_OF_LOSS,\n",
    "    CREATED_DATE, LOSS_DATE, REPORTED_DATE, CLAIMANT_ID, PERFORMER,\n",
    "    POLICY_NO, FNOL_COMPLETION_DATE, LOSS_DESCRIPTION, LOSS_STATE, LOSS_ZIP_CODE\n",
    ") VALUES\n",
    "-- Existing property claim\n",
    "('1899', 'Property', 'Open', 'Hurricane', '2025-01-06', '2025-01-06', '2025-01-06', '19', '18',\n",
    " '888', '2025-01-06', 'Damaged dwelling and fence after the tree fell', 'NJ', '08820'),\n",
    "-- Additional claims\n",
    "('1900', 'Auto', 'Closed', 'Collision', '2025-01-10', '2025-01-09', '2025-01-10', '21', '28',\n",
    " '901', '2025-01-10', 'Rear-end collision at intersection', 'NY', '10001'),\n",
    "('1901', 'Property', 'Open', 'Fire', '2025-02-05', '2025-02-04', '2025-02-05', '22', '38',\n",
    " '902', '2025-02-05', 'Kitchen fire with smoke damage', 'CA', '94105'),\n",
    "('1902', 'Property', 'Pending', 'Theft', '2025-03-12', '2025-03-11', '2025-03-12', '23', '48',\n",
    " '903', '2025-03-12', 'Burglary with electronics stolen', 'TX', '73301'),\n",
    "('1903', 'Auto', 'Open', 'Hail', '2025-04-02', '2025-04-01', '2025-04-02', '24', '58',\n",
    " '904', '2025-04-02', 'Hail damage to vehicle roof and hood', 'CO', '80202');\n",
    "\n",
    "-- Claim lines for each claim\n",
    "INSERT INTO CLAIM_LINES (\n",
    "    CLAIM_NO, LINE_NO, LOSS_DESCRIPTION, CLAIM_STATUS,\n",
    "    CREATED_DATE, REPORTED_DATE, CLAIMANT_ID, PERFORMER_ID\n",
    ") VALUES\n",
    "-- Claim 1899 lines\n",
    "('1899', 16, 'Damaged Dwelling', 'Open', '2025-01-06', '2025-01-06', '19', '171'),\n",
    "('1899', 17, 'Damaged Fence', 'Open', '2025-01-06', '2025-01-06', '19', '181'),\n",
    "('1899', 18, 'Damaged Lawn', 'Open', '2025-01-06', '2025-01-06', '19', '191'),\n",
    "-- Claim 1900 (auto)\n",
    "('1900', 21, 'Rear bumper damage', 'Closed', '2025-01-10', '2025-01-10', '21', '201'),\n",
    "('1900', 22, 'Trunk damage', 'Closed', '2025-01-10', '2025-01-10', '21', '201'),\n",
    "-- Claim 1901 (property fire)\n",
    "('1901', 31, 'Cabinet and appliance damage', 'Open', '2025-02-05', '2025-02-05', '22', '172'),\n",
    "('1901', 32, 'Smoke damage to walls and ceiling', 'Open', '2025-02-05', '2025-02-05', '22', '182'),\n",
    "-- Claim 1902 (theft)\n",
    "('1902', 41, 'Stolen TV and speakers', 'Pending', '2025-03-12', '2025-03-12', '23', '192'),\n",
    "('1902', 42, 'Stolen laptop and phone', 'Pending', '2025-03-12', '2025-03-12', '23', '192'),\n",
    "-- Claim 1903 (hail)\n",
    "('1903', 51, 'Dented hood and roof', 'Open', '2025-04-02', '2025-04-02', '24', '202'),\n",
    "('1903', 52, 'Cracked windshield', 'Open', '2025-04-02', '2025-04-02', '24', '202');\n",
    "\n",
    "-- Financial transactions: reserves and payments per line\n",
    "INSERT INTO FINANCIAL_TRANSACTIONS (\n",
    "    FXID, LINE_NO, FINANCIAL_TYPE, CURRENCY, FIN_TX_AMT, FIN_TX_POST_DT\n",
    ") VALUES\n",
    "-- Claim 1899 financials\n",
    "('21', 16, 'RSV', 'USD', 4000.00, '2025-02-15'),\n",
    "('22', 16, 'PAY', 'USD', 4000.00, '2025-06-15'),\n",
    "('23', 17, 'RSV', 'USD', 3000.00, '2025-03-06'),\n",
    "('24', 17, 'PAY', 'USD', 3500.00, '2025-05-05'),\n",
    "('25', 18, 'RSV', 'USD', 2000.00, '2025-02-15'),\n",
    "('26', 18, 'PAY', 'USD', 2000.00, '2025-04-05'),\n",
    "-- Claim 1900 financials\n",
    "('31', 21, 'RSV', 'USD', 2500.00, '2025-01-11'),\n",
    "('32', 21, 'PAY', 'USD', 2400.00, '2025-01-25'),\n",
    "('33', 22, 'RSV', 'USD', 1500.00, '2025-01-11'),\n",
    "('34', 22, 'PAY', 'USD', 1500.00, '2025-01-28'),\n",
    "-- Claim 1901 financials\n",
    "('41', 31, 'RSV', 'USD', 5000.00, '2025-02-06'),\n",
    "('42', 31, 'PAY', 'USD', 3000.00, '2025-02-20'),\n",
    "('43', 32, 'RSV', 'USD', 2000.00, '2025-02-06'),\n",
    "-- Claim 1902 financials\n",
    "('51', 41, 'RSV', 'USD', 3500.00, '2025-03-13'),\n",
    "('52', 41, 'PAY', 'USD', 2000.00, '2025-03-25'),\n",
    "('53', 42, 'RSV', 'USD', 2500.00, '2025-03-13'),\n",
    "-- Claim 1903 financials\n",
    "('61', 51, 'RSV', 'USD', 1800.00, '2025-04-03'),\n",
    "('62', 51, 'PAY', 'USD', 1700.00, '2025-04-15'),\n",
    "('63', 52, 'RSV', 'USD', 900.00, '2025-04-03'),\n",
    "('64', 52, 'PAY', 'USD', 850.00, '2025-04-18');\n",
    "\n",
    "-- Authorization limits for performers used above\n",
    "INSERT INTO AUTHORIZATION (PERFORMER_ID, FROM_AMT, TO_AMT, CURRENCY) VALUES\n",
    "('171', 0.00, 5000.00, 'USD'),\n",
    "('181', 0.00, 3000.00, 'USD'),\n",
    "('191', 0.00, 2500.00, 'USD'),\n",
    "('201', 0.00, 4000.00, 'USD'),\n",
    "('172', 0.00, 6000.00, 'USD'),\n",
    "('182', 0.00, 3500.00, 'USD'),\n",
    "('192', 0.00, 4000.00, 'USD'),\n",
    "('202', 0.00, 3000.00, 'USD');\n",
    "\n",
    "-- Invoices for each claim line\n",
    "INSERT INTO INVOICES (\n",
    "    INV_ID, INV_LINE_NBR, LINE_NO, DESCRIPTION, CURRENCY, INVOICE_AMOUNT, INVOICE_DATE, VENDOR\n",
    ") VALUES\n",
    "-- Claim 1899 invoices\n",
    "('5', 1, 16, 'Wooden Logs', 'USD', 2500.00, '2025-05-15', 'ABC'),\n",
    "('5', 2, 16, 'Hardware', 'USD', 1000.00, '2025-05-15', 'ABC'),\n",
    "('5', 3, 16, 'Labor', 'USD', 500.00, '2025-05-15', 'ABC'),\n",
    "('6', 1, 17, 'Fence', 'USD', 3000.00, '2025-04-20', 'LMN'),\n",
    "('6', 2, 17, 'Labor', 'USD', 500.00, '2025-04-20', 'LMN'),\n",
    "('7', 1, 18, 'Lawn', 'USD', 1200.00, '2025-03-18', 'XYZ'),\n",
    "('7', 2, 18, 'Equipment Rental', 'USD', 200.00, '2025-03-18', 'XYZ'),\n",
    "('7', 3, 18, 'Labor', 'USD', 600.00, '2025-03-18', 'XYZ'),\n",
    "-- Claim 1900 invoices\n",
    "('8', 1, 21, 'Rear bumper replacement', 'USD', 1800.00, '2025-01-20', 'AUTO_BODY_INC'),\n",
    "('8', 2, 21, 'Paint and materials', 'USD', 400.00, '2025-01-20', 'AUTO_BODY_INC'),\n",
    "('9', 1, 22, 'Trunk repair', 'USD', 900.00, '2025-01-22', 'AUTO_BODY_INC'),\n",
    "('9', 2, 22, 'Labor', 'USD', 600.00, '2025-01-22', 'AUTO_BODY_INC'),\n",
    "-- Claim 1901 invoices\n",
    "('10', 1, 31, 'Cabinet replacement', 'USD', 2500.00, '2025-02-15', 'HOME_REMODELERS'),\n",
    "('10', 2, 31, 'Appliance replacement', 'USD', 1800.00, '2025-02-15', 'HOME_REMODELERS'),\n",
    "('11', 1, 32, 'Smoke remediation', 'USD', 1500.00, '2025-02-18', 'RESTORE_CO'),\n",
    "-- Claim 1902 invoices\n",
    "('12', 1, 41, 'Electronics replacement', 'USD', 2200.00, '2025-03-20', 'ELEC_WORLD'),\n",
    "('12', 2, 41, 'Installation', 'USD', 400.00, '2025-03-20', 'ELEC_WORLD'),\n",
    "('13', 1, 42, 'Laptop replacement', 'USD', 1500.00, '2025-03-21', 'TECH_STORE'),\n",
    "('13', 2, 42, 'Phone replacement', 'USD', 800.00, '2025-03-21', 'TECH_STORE'),\n",
    "-- Claim 1903 invoices\n",
    "('14', 1, 51, 'Body repair and paint', 'USD', 1600.00, '2025-04-12', 'HAIL_REPAIR_CO'),\n",
    "('14', 2, 51, 'Rental car', 'USD', 300.00, '2025-04-12', 'RENTAL_CORP'),\n",
    "('15', 1, 52, 'Windshield replacement', 'USD', 900.00, '2025-04-14', 'GLASS_SHOP');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parse Documents with Cortex (PARSE_DOCUMENT & EXTRACT_ANSWER)\n",
    "\n",
    "In this section you will:\n",
    "- Use **`SNOWFLAKE.CORTEX.PARSE_DOCUMENT`** to convert uploaded PDFs/images into extracted text.\n",
    "- Use **`SNOWFLAKE.CORTEX.EXTRACT_ANSWER`** to pull out specific fields (like claim numbers) from that text.\n",
    "- Populate three structured tables: `PARSED_CLAIM_NOTES`, `PARSED_GUIDELINES`, and `PARSED_INVOICES`.\n",
    "\n",
    "### How PARSE_DOCUMENT works\n",
    "- `SNOWFLAKE.CORTEX.PARSE_DOCUMENT(@stage, relative_path, {'mode': 'OCR'})`:\n",
    "  - Reads the file from a **Snowflake stage** (here `@INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE`).\n",
    "  - Runs **OCR and layout-aware parsing** to extract readable text.\n",
    "  - Returns a **VARIANT** result, from which we pull the `:content` field and cast to `VARCHAR`.\n",
    "\n",
    "### How EXTRACT_ANSWER works\n",
    "- `SNOWFLAKE.CORTEX.EXTRACT_ANSWER(extracted_content, 'What is the claim number?')`:\n",
    "  - Takes free-form text (from `PARSE_DOCUMENT`).\n",
    "  - Uses an LLM to answer a **targeted question** (e.g., claim number or ID).\n",
    "  - Returns a JSON array of candidate answers with **`answer`** and **`score`**.\n",
    "- In the SQL cells below, we:\n",
    "  - **FLATTEN** that JSON array.\n",
    "  - Filter to rows where `score >= 0.5`.\n",
    "  - Store the chosen `answer` as `CLAIM_NO` in parsed tables.\n",
    "\n",
    "For more details, see `https://docs.snowflake.com` and search for **\"SNOWFLAKE.CORTEX.PARSE_DOCUMENT\"** and **\"SNOWFLAKE.CORTEX.EXTRACT_ANSWER\"**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "LS @INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000021",
   "metadata": {
    "language": "sql",
    "name": "cell22",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 1.1 Parse claim notes and extract claim numbers into PARSED_CLAIM_NOTES\n",
    "CREATE OR REPLACE TABLE PARSED_CLAIM_NOTES (\n",
    "    FILENAME VARCHAR(255),\n",
    "    EXTRACTED_CONTENT VARCHAR(16777216),\n",
    "    PARSE_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP,\n",
    "    CLAIM_NO VARCHAR\n",
    ");\n",
    "\n",
    "INSERT INTO PARSED_CLAIM_NOTES (FILENAME, EXTRACTED_CONTENT, CLAIM_NO)\n",
    "SELECT\n",
    "    t1.RELATIVE_PATH AS FILENAME,\n",
    "    t1.EXTRACTED_CONTENT,\n",
    "    flattened.value:answer::VARCHAR AS CLAIM_NO\n",
    "FROM\n",
    "    (\n",
    "        SELECT\n",
    "            RELATIVE_PATH,\n",
    "            TO_VARCHAR(\n",
    "                SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "                    '@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence',\n",
    "                    RELATIVE_PATH,\n",
    "                    {'mode': 'OCR'}\n",
    "                ):content\n",
    "            ) AS EXTRACTED_CONTENT\n",
    "        FROM\n",
    "            DIRECTORY('@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence')\n",
    "        WHERE\n",
    "            RELATIVE_PATH LIKE '%Claim_Note%'\n",
    "    ) AS t1,\n",
    "    LATERAL FLATTEN(\n",
    "        input => SNOWFLAKE.CORTEX.EXTRACT_ANSWER(t1.EXTRACTED_CONTENT, 'What is the claim number?')\n",
    "    ) AS flattened\n",
    "WHERE\n",
    "    flattened.value:score::NUMBER >= 0.5;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000022",
   "metadata": {
    "language": "sql",
    "name": "cell23",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 1.2 Parse guidelines documents into PARSED_GUIDELINES\n",
    "CREATE OR REPLACE TABLE PARSED_GUIDELINES (\n",
    "    FILENAME VARCHAR(255),\n",
    "    EXTRACTED_CONTENT VARCHAR(16777216), \n",
    "    PARSE_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP\n",
    ");\n",
    "\n",
    "INSERT INTO PARSED_GUIDELINES (FILENAME, EXTRACTED_CONTENT)\n",
    "SELECT\n",
    "    t1.RELATIVE_PATH AS FILENAME,\n",
    "    TO_VARCHAR(\n",
    "        SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "            '@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence',\n",
    "            t1.RELATIVE_PATH,\n",
    "            {'mode': 'OCR'}\n",
    "        ):content\n",
    "    ) AS EXTRACTED_CONTENT\n",
    "FROM\n",
    "    DIRECTORY('@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence') AS t1\n",
    "WHERE\n",
    "    t1.RELATIVE_PATH LIKE '%Guideline%';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000023",
   "metadata": {
    "language": "sql",
    "name": "cell24",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 1.3 Parse invoices and extract claim numbers into PARSED_INVOICES\n",
    "CREATE OR REPLACE TABLE PARSED_INVOICES (\n",
    "    FILENAME VARCHAR(255),\n",
    "    EXTRACTED_CONTENT VARCHAR(16777216), \n",
    "    PARSE_DATE TIMESTAMP_NTZ DEFAULT CURRENT_TIMESTAMP,\n",
    "    CLAIM_NO VARCHAR\n",
    ");\n",
    "\n",
    "INSERT INTO PARSED_INVOICES (FILENAME, EXTRACTED_CONTENT, CLAIM_NO)\n",
    "SELECT\n",
    "    t1.RELATIVE_PATH,\n",
    "    t1.EXTRACTED_CONTENT,\n",
    "    flattened.value:answer::VARCHAR AS CLAIM_NO\n",
    "FROM\n",
    "    (\n",
    "        SELECT\n",
    "            RELATIVE_PATH,\n",
    "            TO_VARCHAR(\n",
    "                SNOWFLAKE.CORTEX.PARSE_DOCUMENT(\n",
    "                    '@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence',\n",
    "                    RELATIVE_PATH,\n",
    "                    {'mode': 'OCR'}\n",
    "                ):content\n",
    "            ) AS EXTRACTED_CONTENT\n",
    "        FROM\n",
    "            DIRECTORY('@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence')\n",
    "        WHERE\n",
    "            RELATIVE_PATH LIKE '%invoice%'\n",
    "    ) AS t1,\n",
    "    LATERAL FLATTEN(\n",
    "        input => SNOWFLAKE.CORTEX.EXTRACT_ANSWER(t1.EXTRACTED_CONTENT, 'What is the claim no?')\n",
    "    ) AS flattened\n",
    "WHERE\n",
    "    flattened.value:score::NUMBER >= 0.5;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000024",
   "metadata": {
    "name": "cell25"
   },
   "source": [
    "## 2. Chunk Documents and Build Cortex Search Indexes (Cortex Search)\n",
    "\n",
    "In this section you will:\n",
    "- Break parsed **claim notes** and **guidelines** into small overlapping text chunks.\n",
    "- Generate **presigned URLs** for each source file so end users can drill back into raw documents.\n",
    "- Create **Cortex Search Services** over these chunks for semantic retrieval by the agent.\n",
    "\n",
    "### What is Cortex Search?\n",
    "- **Cortex Search** is Snowflake’s **vector + keyword search engine** for unstructured and semi-structured content.\n",
    "- It automatically embeds each `chunk` of text using a selected **embedding model** (here: `snowflake-arctic-embed-l-v2.0`).\n",
    "- You create a **CORTEX SEARCH SERVICE** that points at a base table (`NOTES_CHUNK_TABLE`, `GUIDELINES_CHUNK_TABLE`) and declares:\n",
    "  - The **text column** to index (`chunk`).\n",
    "  - Optional **attribute columns** (`file_url`, `claim_no`, `filename`) that are returned alongside search results.\n",
    "\n",
    "The Insurance Claims Agent will later call these search services to:\n",
    "- Retrieve **relevant claim notes** for a given claim number.\n",
    "- Look up **jurisdictional or company guidelines** that apply to a given scenario.\n",
    "\n",
    "For more details, see the Snowflake documentation at `https://docs.snowflake.com` and search for **\"Cortex Search\"** and **\"SPLIT_TEXT_RECURSIVE_CHARACTER\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000025",
   "metadata": {
    "language": "sql",
    "name": "cell26",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 2.1 Chunk claim notes and create NOTES_CHUNK_TABLE\n",
    "CREATE OR REPLACE TABLE NOTES_CHUNK_TABLE AS\n",
    "SELECT\n",
    "    FILENAME,\n",
    "    CLAIM_NO,\n",
    "    GET_PRESIGNED_URL('@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence', FILENAME, 86400) AS file_url,\n",
    "    CONCAT(FILENAME, ': ', c.value::TEXT) AS chunk,\n",
    "    'English' AS language\n",
    "FROM\n",
    "    PARSED_CLAIM_NOTES,\n",
    "    LATERAL FLATTEN(SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n",
    "        EXTRACTED_CONTENT,\n",
    "        'markdown',\n",
    "        200, -- chunks of 200 characters\n",
    "        30   -- 30 character overlap\n",
    "    )) c;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000026",
   "metadata": {
    "language": "sql",
    "name": "cell27",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 2.2 Chunk guidelines and create GUIDELINES_CHUNK_TABLE\n",
    "CREATE OR REPLACE TABLE GUIDELINES_CHUNK_TABLE AS\n",
    "SELECT\n",
    "    FILENAME,\n",
    "    GET_PRESIGNED_URL('@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence', FILENAME, 86400) AS file_url,\n",
    "    CONCAT(FILENAME, ': ', c.value::TEXT) AS chunk,\n",
    "    'English' AS language\n",
    "FROM\n",
    "    PARSED_GUIDELINES,\n",
    "    LATERAL FLATTEN(SNOWFLAKE.CORTEX.SPLIT_TEXT_RECURSIVE_CHARACTER(\n",
    "        EXTRACTED_CONTENT,\n",
    "        'markdown',\n",
    "        200, -- chunks of 200 characters\n",
    "        30   -- 30 character overlap\n",
    "    )) c;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000027",
   "metadata": {
    "language": "sql",
    "name": "cell28",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 2.3 Create Cortex Search Services over claim notes and guidelines\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE INSURANCE_CLAIMS_DEMO_claim_notes\n",
    "  ON chunk\n",
    "  ATTRIBUTES file_url, claim_no, filename\n",
    "  WAREHOUSE = CLAIMS_AGENT_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "    chunk,\n",
    "    file_url,\n",
    "    claim_no,\n",
    "    filename\n",
    "  FROM NOTES_CHUNK_TABLE\n",
    ");\n",
    "\n",
    "CREATE OR REPLACE CORTEX SEARCH SERVICE INSURANCE_CLAIMS_DEMO_guidelines\n",
    "  ON chunk\n",
    "  ATTRIBUTES file_url, filename\n",
    "  WAREHOUSE = CLAIMS_AGENT_WH\n",
    "  TARGET_LAG = '1 hour'\n",
    "  EMBEDDING_MODEL = 'snowflake-arctic-embed-l-v2.0'\n",
    "AS (\n",
    "  SELECT\n",
    "     chunk,\n",
    "     file_url,\n",
    "     filename\n",
    "  FROM GUIDELINES_CHUNK_TABLE\n",
    ");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Optional -  Create a Cortex Search Service from the Snowsight UI\n",
    "\n",
    "You can also create the Cortex Search service for claim notes and guidelines directly from the Snowsight UI (AI & ML Studio), instead of only using SQL. The UI-driven configuration below will produce the same `INSURANCE_CLAIMS_DEMO_claim_notes` service as the SQL script in the next cell.\n",
    "\n",
    "1. **Open AI & ML Studio**\n",
    "   - Navigate to **AI & ML** in the primary Snowsight navigation menu.\n",
    "   - Select **Search** to open **Cortex Search**.\n",
    "\n",

    "2. **Start a new Cortex Search Service**\n",
    "   - In the **\"Create a Cortex Search Service\"** tile, select **+ Create**.\n",
    "\n",

    "3. **Configure basic settings**\n",
    "   - **Database & Schema**: Choose `INSURANCE_CLAIMS_DEMO` as the **Database** and `LOSS_CLAIMS` as the **Schema** (this is where the service object will be created).\n",
    "   - **Service Name**: Enter a descriptive name such as **`TEST_INSURANCE_CLAIMS_DEMO_claim_notes`**, then select **Next**.\n",
    "\n",

    "4. **Select data to be indexed**\n",
    "   - For **Source table or view**, select the `NOTES_CHUNK_TABLE` created in step **2.1**.\n",
    "   - Select **Next**.\n",
    "\n",

    "5. **Select search and attribute columns**\n",
    "   - **Select a search column **: Choose the text column that will be the primary source for semantic and keyword search, e.g. **`CHUNK`**.\n",
    "   - **select attributes columns**: Select a set of columns that you'd wish to use as filters when querying the service, for example:\n",
    "     - `LANGUAGE`\n",
    "     - `FILE_URL`\n",
    "     - `CLAIM_NO`\n",
    "   - Select **Next**.\n",
    "   - Select **Next**.\n",

    "6. **Configure your Search Service**\n",
    "   - **Target Lag**: Set the **Target Lag** (for example `1 hour`) to control how quickly the search index catches up with changes in `NOTES_CHUNK_TABLE`.\n",
    "   - **Embedding model**: Select snowflake-arctic-embed-l-v2.0 model from dropdown.\n",
    "   - **Warehouse for indexing **: Select CLAIMS_AGENT_WH.\n",
    "   - Select **Create** to provision the Cortex Search service.\n",
    "\n",

    "After this, your UI-created service `TEST_INSURANCE_CLAIMS_DEMO_claim_notes` will be functionally equivalent to the service created by the SQL script in section **2.3** below. Follow similar step to create INSURANCE_CLAIMS_DEMO_guidelines search service.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000028",
   "metadata": {
    "name": "cell29"
   },
   "source": [
    "## 3. Helper AI Functions and Procedures\n",
    "\n",
    "In this section you will:\n",
    "- Create reusable **SQL functions** for document classification, parsing, and image summarization.\n",
    "- Create a **stored procedure** to transcribe audio files using **AI_TRANSCRIBE**.\n",
    "\n",
    "For details, search the Snowflake docs for **\"AI_EXTRACT\"**, **\"AI_PARSE_DOCUMENT\"**, **\"SNOWFLAKE.CORTEX.COMPLETE\"**, and **\"AI_TRANSCRIBE\"**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000029",
   "metadata": {
    "language": "sql",
    "name": "cell30",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 3.1 Function: CLASSIFY_DOCUMENT – classify documents stored in the LOSS_EVIDENCE stage\n",
    "CREATE OR REPLACE FUNCTION INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.CLASSIFY_DOCUMENT(\n",
    "    \"FILE_NAME\" VARCHAR,\n",
    "    \"STAGE_NAME\" VARCHAR DEFAULT '@INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE'\n",
    ")\n",
    "RETURNS OBJECT\n",
    "LANGUAGE SQL\n",
    "AS '\n",
    "    WITH classification_result AS (\n",
    "        SELECT AI_EXTRACT(\n",
    "            TO_FILE(stage_name, file_name),\n",
    "            [\n",
    "                ''What type of document is this? Classify as one of: Invoice, Evidence Image, Medical Bill, Insurance Claim, Policy Document, Correspondence, Legal Document, Financial Statement, Other''\n",
    "            ]\n",
    "        ) as classification_data\n",
    "    )\n",
    "    SELECT \n",
    "        OBJECT_CONSTRUCT(\n",
    "            ''success'', TRUE,\n",
    "            ''file_name'', file_name,\n",
    "            ''classification_type'', classification_data[0]:answer::STRING,\n",
    "            ''description'', classification_data[1]:answer::STRING,\n",
    "            ''business_context'', classification_data[2]:answer::STRING,\n",
    "            ''document_purpose'', classification_data[3]:answer::STRING,\n",
    "            ''confidence_score'', (\n",
    "                classification_data[0]:score::NUMBER + \n",
    "                classification_data[1]:score::NUMBER + \n",
    "                classification_data[2]:score::NUMBER + \n",
    "                classification_data[3]:score::NUMBER\n",
    "            ) / 4,\n",
    "            ''classification_timestamp'', CURRENT_TIMESTAMP(),\n",
    "            ''full_classification_data'', classification_data\n",
    "        ) as result\n",
    "    FROM classification_result\n",
    "';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000030",
   "metadata": {
    "language": "sql",
    "name": "cell31",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 3.2 Function: PARSE_DOCUMENT_FROM_STAGE – parse a document from LOSS_EVIDENCE\n",
    "CREATE OR REPLACE FUNCTION INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.PARSE_DOCUMENT_FROM_STAGE(\n",
    "    \"FILE_NAME\" VARCHAR\n",
    ")\n",
    "RETURNS VARIANT\n",
    "LANGUAGE SQL\n",
    "AS '\n",
    "    SELECT AI_PARSE_DOCUMENT(\n",
    "        TO_FILE(''@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence'', file_name),\n",
    "        {\n",
    "            ''mode'': ''LAYOUT'',\n",
    "            ''page_split'': TRUE\n",
    "        }\n",
    "    )::VARIANT\n",
    "';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000031",
   "metadata": {
    "language": "sql",
    "name": "cell32",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 3.3 Function: GET_IMAGE_SUMMARY – summarize an image using Cortex COMPLETE\n",
    "CREATE OR REPLACE FUNCTION INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.GET_IMAGE_SUMMARY(\n",
    "    \"IMAGE_FILE\" VARCHAR,\n",
    "    \"STAGE_NAME\" VARCHAR\n",
    ")\n",
    "RETURNS VARCHAR\n",
    "LANGUAGE SQL\n",
    "AS '\n",
    "    SELECT SNOWFLAKE.CORTEX.COMPLETE(\n",
    "        ''claude-3-5-sonnet'',\n",
    "        ''Summarize the key insights from the attached image in 100 words.'',\n",
    "        TO_FILE(''@'' || STAGE_NAME || ''/'' || IMAGE_FILE)\n",
    "    )\n",
    "';\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000032",
   "metadata": {
    "language": "sql",
    "name": "cell33",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 3.4 Procedure: TRANSCRIBE_AUDIO_SIMPLE – transcribe audio from a stage file\n",
    "CREATE OR REPLACE PROCEDURE INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.TRANSCRIBE_AUDIO_SIMPLE(\n",
    "    \"FILE_NAME\" VARCHAR,\n",
    "    \"STAGE_NAME\" VARCHAR DEFAULT '@loss_evidence'\n",
    ")\n",
    "RETURNS OBJECT\n",
    "LANGUAGE SQL\n",
    "EXECUTE AS OWNER\n",
    "AS '\n",
    "BEGIN\n",
    "    -- Use AI_TRANSCRIBE with speaker-level timestamps\n",
    "    RETURN (\n",
    "        WITH transcription_query AS (\n",
    "            SELECT \n",
    "                :file_name as fn,\n",
    "                :stage_name as sn,\n",
    "                AI_TRANSCRIBE(\n",
    "                    TO_FILE(:stage_name, :file_name),\n",
    "                    PARSE_JSON(''{\"timestamp_granularity\": \"speaker\"}'')\n",
    "                ) as transcription_result\n",
    "        )\n",
    "        SELECT OBJECT_CONSTRUCT(\n",
    "            ''success'', TRUE,\n",
    "            ''file_name'', fn,\n",
    "            ''stage_name'', sn,\n",
    "            ''transcription'', transcription_result,\n",
    "            ''transcription_timestamp'', CURRENT_TIMESTAMP()\n",
    "        )\n",
    "        FROM transcription_query\n",
    "    );\n",
    "EXCEPTION\n",
    "    WHEN OTHER THEN\n",
    "        RETURN OBJECT_CONSTRUCT(\n",
    "            ''success'', FALSE,\n",
    "            ''file_name'', :file_name,\n",
    "            ''stage_name'', :stage_name,\n",
    "            ''error_code'', SQLCODE,\n",
    "            ''error_message'', SQLERRM,\n",
    "            ''transcription_timestamp'', CURRENT_TIMESTAMP()\n",
    "        );\n",
    "END;\n",
    "';\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000033",
   "metadata": {
    "name": "cell34"
   },
   "source": [
    "## 4. Cortex Analyst Semantic View over Claims Data\n",
    "\n",
    "In this section you will:\n",
    "- Create a **semantic view** `CA_INSURANCE_CLAIMS_DEMO` over the core claims tables.\n",
    "- Declare **relationships, facts, and dimensions** that describe how claims, lines, financials, authorizations, and invoices relate.\n",
    "- Provide **sample values and verified queries** to guide **Cortex Analyst** when generating SQL.\n",
    "\n",
    "### What is a Cortex Analyst semantic view?\n",
    "- **Cortex Analyst** turns natural language questions into **safe, optimized SQL** using a **semantic model** instead of raw table metadata.\n",
    "- A **semantic view**:\n",
    "  - Lists all **tables** the model is allowed to query.\n",
    "  - Defines **relationships** (joins) between tables.\n",
    "  - Labels important numeric columns as **facts** and categorical/time columns as **dimensions**.\n",
    "  - Optionally includes **synonyms, comments, sample values, and verified queries** to steer the model.\n",
    "- In this lab, `CA_INSURANCE_CLAIMS_DEMO` tells Cortex Analyst how to join `CLAIMS`, `CLAIM_LINES`, `FINANCIAL_TRANSACTIONS`, `AUTHORIZATION`, and `INVOICES` to answer audit questions.\n",
    "\n",
    "For more details, see the Snowflake documentation at `https://docs.snowflake.com` and search for **\"Cortex Analyst\"** and **\"semantic model\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000034",
   "metadata": {
    "language": "sql",
    "name": "cell35",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 4.1 Create the semantic view CA_INSURANCE_CLAIMS_DEMO for Cortex Analyst\n",
    "CREATE OR REPLACE SEMANTIC VIEW INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.CA_INSURANCE_CLAIMS_DEMO\n",
    "    TABLES (\n",
    "        AUTHORIZATION PRIMARY KEY (PERFORMER_ID),\n",
    "        CLAIMS PRIMARY KEY (CLAIM_NO),\n",
    "        CLAIM_LINES PRIMARY KEY (LINE_NO),\n",
    "        FINANCIAL_TRANSACTIONS PRIMARY KEY (LINE_NO),\n",
    "        INVOICES\n",
    "    )\n",
    "    RELATIONSHIPS (\n",
    "        CLAIM_LINES_TO_AUTHORIZATION AS CLAIM_LINES(PERFORMER_ID) REFERENCES AUTHORIZATION(PERFORMER_ID),\n",
    "        CLAIM_TO_CLAIM_LINES_CLAIM_ID AS CLAIM_LINES(CLAIM_NO) REFERENCES CLAIMS(CLAIM_NO),\n",
    "        FINANCIAL_TO_CLAIM_LINES AS CLAIM_LINES(LINE_NO) REFERENCES FINANCIAL_TRANSACTIONS(LINE_NO),\n",
    "        CLAIM_LINES_TO_INVOICE AS INVOICES(LINE_NO) REFERENCES CLAIM_LINES(LINE_NO),\n",
    "        FINANCIAL_TO_INVOICE AS INVOICES(LINE_NO) REFERENCES FINANCIAL_TRANSACTIONS(LINE_NO)\n",
    "    )\n",
    "    FACTS (\n",
    "        AUTHORIZATION.FROM_AMT AS FROM_AMT WITH SYNONYMS=('beginning_balance','initial_amount','lower_bound_amount','minimum_amount','starting_amount') COMMENT='The amount of funds being transferred or allocated from one account or source to another.',\n",
    "        AUTHORIZATION.TO_AMT AS TO_AMT WITH SYNONYMS=('ceiling_amount','end_amount','end_value','max_value','maximum_amount','to_value','upper_bound','upper_limit') COMMENT='The total amount of the authorization.',\n",
    "        FINANCIAL_TRANSACTIONS.FIN_TX_AMT AS FIN_TX_AMT WITH SYNONYMS=('amount_transacted','financial_amount','financial_transaction_value','payment_amount','transaction_amount','transaction_cost','transaction_value') COMMENT='The amount of the financial transaction.',\n",
    "        INVOICES.INVOICE_AMOUNT AS INVOICE_AMOUNT WITH SYNONYMS=('amount_billed','billed_amount','invoice_cost','invoice_price','invoice_total','invoice_value','total_due','total_invoice_value') COMMENT='The total amount due on an invoice, representing the sum of all charges, taxes, and fees associated with a specific transaction or order.'\n",
    "    )\n",
    "    DIMENSIONS (\n",
    "        AUTHORIZATION.CURRENCY AS CURRENCY WITH SYNONYMS=('bill_type','coin_type','denomination','exchange_unit','legal_tender','monetary_unit','money_unit','tender_type') COMMENT='The currency in which the transaction or authorization was processed.',\n",
    "        AUTHORIZATION.PERFORMER_ID AS PERFORMER_ID WITH SYNONYMS=('account_id','actor_id','executor_id','operator_id','performer_key','practitioner_id','provider_id','user_id') COMMENT='Unique identifier for the individual or entity responsible for performing a specific task or action.',\n",
    "        CLAIMS.CAUSE_OF_LOSS AS CAUSE_OF_LOSS WITH SYNONYMS=('accident_cause','claim_cause','claim_reason','damage_cause','incident_cause','loss_cause','loss_origin','loss_reason','reason_for_claim') COMMENT='The reason or event that triggered the insurance claim, such as a natural disaster or accident.',\n",
    "        CLAIMS.CLAIMANT_ID AS CLAIMANT_ID WITH SYNONYMS=('claimant_identifier','claimant_number','insured_id','insured_party_id','policy_owner_id','policyholder_id') COMMENT='Unique identifier for the individual or entity submitting the claim.',\n",
    "        CLAIMS.CLAIM_NO AS CLAIM_NO WITH SYNONYMS=('claim_id','claim_identifier','claim_number','claim_reference','policy_claim_number') COMMENT='Unique identifier for a claim, used to distinguish one claim from another.',\n",
    "        CLAIMS.CLAIM_STATUS AS CLAIM_STATUS WITH SYNONYMS=('claim_decision','claim_disposition','claim_outcome','claim_resolution','claim_result','claim_state','claim_verdict') COMMENT='The current status of the claim, indicating whether it is still being processed (Open) or has been resolved.',\n",
    "        CLAIMS.CREATED_DATE AS CREATED_DATE WITH SYNONYMS=('created_timestamp','creation_date','date_created','entry_date','insertion_date','record_date','registration_date','submission_date') COMMENT='Date when the claim was created.',\n",
    "        CLAIMS.FNOL_COMPLETION_DATE AS FNOL_COMPLETION_DATE WITH SYNONYMS=('first_notice_of_loss_completion_date','first_report_of_loss_date','initial_loss_report_date','loss_notification_completion_date','notice_of_loss_completion_date') COMMENT='Date when the First Notice of Loss (FNOL) was completed, marking the initial report of a claim.',\n",
    "        CLAIMS.LINE_OF_BUSINESS AS LINE_OF_BUSINESS WITH SYNONYMS=('business_line','business_segment','industry','market_segment','product_category','product_line','service_category','service_line') COMMENT='The type of business or industry that the claim is related to, such as property, casualty, or liability.',\n",
    "        CLAIMS.LOSS_DATE AS LOSS_DATE WITH SYNONYMS=('accident_date','date_of_incident','date_of_loss','incident_date','loss_event_date','loss_occurrence_date') COMMENT='Date on which the loss or damage occurred.',\n",
    "        CLAIMS.LOSS_DESCRIPTION AS LOSS_DESCRIPTION WITH SYNONYMS=('claim_description','claim_summary','damage_description','incident_description','incident_summary','loss_details','loss_narrative','loss_summary') COMMENT='A brief description of the loss or damage that occurred, as reported by the claimant.',\n",
    "        CLAIMS.LOSS_STATE AS LOSS_STATE WITH SYNONYMS=('location_of_loss','loss_location','loss_region','loss_state_province','loss_territory','state_of_loss','state_where_loss_occurred') COMMENT='The state in which the loss occurred.',\n",
    "        CLAIMS.LOSS_ZIP_CODE AS LOSS_ZIP_CODE WITH SYNONYMS=('claim_zip_code','incident_zip','loss_location_zip','loss_postal_code','loss_postcode','loss_zip') COMMENT='The five-digit zip code where the loss occurred.',\n",
    "        CLAIMS.PERFORMER AS PERFORMER WITH SYNONYMS=('caregiver','doctor','healthcare_provider','medical_professional','nurse','practitioner','provider','service_provider','therapist') COMMENT='The individual or entity that performed the medical service or procedure associated with the claim.',\n",
    "        CLAIMS.POLICY_NO AS POLICY_NO WITH SYNONYMS=('contract_id','contract_number','policy_code','policy_id','policy_identifier','policy_number') COMMENT='Unique identifier for the insurance policy associated with the claim.',\n",
    "        CLAIMS.REPORTED_DATE AS REPORTED_DATE WITH SYNONYMS=('claim_reported_date','date_reported','filing_date','incident_reported_date','logged_date','notification_date','reported_on','submission_date') COMMENT='The date on which the claim was reported to the organization.',\n",
    "        CLAIM_LINES.CLAIMANT_ID AS CLAIMANT_ID WITH SYNONYMS=('claimant_identifier','claimant_number','claimer_id','insured_id','policy_holder_id','policy_owner_id') COMMENT='Unique identifier for the individual or entity submitting the claim.',\n",
    "        CLAIM_LINES.CLAIM_NO AS CLAIM_NO WITH SYNONYMS=('claim_code','claim_id','claim_identifier','claim_number','claim_reference','policy_number') COMMENT='Unique identifier for a claim, used to track and manage individual claims submitted by patients or healthcare providers for reimbursement or insurance coverage.',\n",
    "        CLAIM_LINES.CLAIM_STATUS AS CLAIM_STATUS WITH SYNONYMS=('claim_disposition','claim_outcome','claim_phase','claim_progress','claim_resolution','claim_result','claim_state') COMMENT='The current status of a claim, indicating whether it is still being processed (Open) or has been resolved.',\n",
    "        CLAIM_LINES.LINE_NO AS LINE_NO WITH SYNONYMS=('claim_line_number','line_number','record_number','row_number','sequence_number') COMMENT='Unique identifier for each line item within a claim.',\n",
    "        CLAIM_LINES.LOSS_DESCRIPTION AS LOSS_DESCRIPTION WITH SYNONYMS=('claim_cause','claim_description','damage_description','incident_description','incident_summary','loss_reason','loss_summary') COMMENT='A brief description of the damage or loss incurred by the policyholder, as reported on the claim.',\n",
    "        CLAIM_LINES.CREATED_DATE AS CREATED_DATE WITH SYNONYMS=('creation_date','date_created','date_entered','date_recorded','entry_date','record_date','registration_date') COMMENT='Date when the claim line was created.',\n",
    "        CLAIM_LINES.PERFORMER_ID AS PERFORMER_ID WITH SYNONYMS=('caregiver_id','healthcare_provider_id','medical_professional_id','practitioner_id','provider_id','service_provider_id') COMMENT='The unique identifier of the healthcare provider who performed the medical service or procedure associated with the claim line.',\n",
    "        CLAIM_LINES.REPORTED_DATE AS REPORTED_DATE WITH SYNONYMS=('date_reported','event_date','filing_date','incident_date','logged_date','occurrence_date','reported_on','submission_date') COMMENT='The date on which the claim was reported to the insurance company.',\n",
    "        FINANCIAL_TRANSACTIONS.CURRENCY AS CURRENCY WITH SYNONYMS=('coin_type','denomination','exchange_unit','legal_tender','medium_of_exchange','monetary_unit','money_unit','tender_type') COMMENT='The currency in which the financial transaction was made.',\n",
    "        FINANCIAL_TRANSACTIONS.FINANCIAL_TYPE AS FINANCIAL_TYPE WITH SYNONYMS=('account_type','financial_category','financial_classification','payment_method','transaction_classification','transaction_type') COMMENT='The type of financial transaction, either a Revenue Share Voucher (RSV) or a payment (PAY).',\n",
    "        FINANCIAL_TRANSACTIONS.FIN_TX_POST_DT AS FIN_TX_POST_DT WITH SYNONYMS=('financial_transaction_date','posting_date','posting_timestamp','transaction_date','transaction_posted_date','transaction_posting_date') COMMENT='Date the financial transaction was posted.',\n",
    "        FINANCIAL_TRANSACTIONS.FXID AS FXID WITH SYNONYMS=('exchange_id','exchange_transaction_key','financial_exchange_identifier','foreign_exchange_id','transaction_id') COMMENT='Unique identifier for a foreign exchange transaction.',\n",
    "        FINANCIAL_TRANSACTIONS.LINE_NO AS LINE_NO WITH SYNONYMS=('entry_number','line_number','record_number','row_number','sequence_number','transaction_line') COMMENT='A unique identifier for each line item within a financial transaction.',\n",
    "        INVOICES.CURRENCY AS CURRENCY WITH SYNONYMS=('coin_type','denomination','exchange_rate_unit','legal_tender','monetary_denomination','monetary_unit','money_unit','tender_type') COMMENT='The currency in which the invoice was issued.',\n",
    "        INVOICES.DESCRIPTION AS DESCRIPTION WITH SYNONYMS=('item_description','item_info','item_note','item_text','product_details','product_info','product_note') COMMENT='A categorization of the type of goods or services billed to a customer, such as materials, equipment, or work performed.',\n",
    "        INVOICES.INVOICE_DATE AS INVOICE_DATE WITH SYNONYMS=('bill_date','billing_date','date_invoiced','document_date','invoice_creation_date','payment_due_date') COMMENT='Date the invoice was issued.',\n",
    "        INVOICES.INV_ID AS INV_ID WITH SYNONYMS=('invoice_code','invoice_id','invoice_identifier','invoice_number','invoice_reference') COMMENT='Unique identifier for each invoice.',\n",
    "        INVOICES.INV_LINE_NBR AS INV_LINE_NBR WITH SYNONYMS=('invoice_item_number','invoice_line_id','invoice_line_number','item_number','line_item_number','line_nbr') COMMENT='Unique identifier for each line item on an invoice.',\n",
    "        INVOICES.LINE_NO AS LINE_NO WITH SYNONYMS=('entry_number','item_number','line_item_number','line_number','row_number','sequence_number') COMMENT='A unique identifier for each line item on an invoice, representing the sequential order in which the items appear on the invoice.',\n",
    "        INVOICES.VENDOR AS VENDOR WITH SYNONYMS=('contractor','dealer','distributor','manufacturer','merchant','provider','seller','supplier','trader') COMMENT='The name of the vendor or supplier that the invoice is associated with.'\n",
    "    )\n",
    "    WITH EXTENSION (CA='{\"tables\":[{\"name\":\"AUTHORIZATION\",\"dimensions\":[{\"name\":\"CURRENCY\",\"sample_values\":[\"USD\"]},{\"name\":\"PERFORMER_ID\",\"sample_values\":[\"181\",\"171\",\"191\"]}],\"facts\":[{\"name\":\"FROM_AMT\",\"sample_values\":[\"0.00\"]},{\"name\":\"TO_AMT\",\"sample_values\":[\"3000.00\",\"2500.00\",\"5000.00\"]}]},{\"name\":\"CLAIMS\",\"dimensions\":[{\"name\":\"CAUSE_OF_LOSS\",\"sample_values\":[\"Hurricane\"]},{\"name\":\"CLAIM_NO\",\"sample_values\":[\"1899\"]},{\"name\":\"CLAIM_STATUS\",\"sample_values\":[\"Open\"]},{\"name\":\"CLAIMANT_ID\",\"sample_values\":[\"19\"]},{\"name\":\"LINE_OF_BUSINESS\",\"sample_values\":[\"Property\"]},{\"name\":\"LOSS_DESCRIPTION\",\"sample_values\":[\"Damaged dwelling and fence after the tree fell\"]},{\"name\":\"LOSS_STATE\",\"sample_values\":[\"NJ\"]},{\"name\":\"LOSS_ZIP_CODE\",\"sample_values\":[\"8820\"]},{\"name\":\"PERFORMER\",\"sample_values\":[\"18\"]},{\"name\":\"POLICY_NO\",\"sample_values\":[\"888\"]}],\"time_dimensions\":[{\"name\":\"CREATED_DATE\",\"sample_values\":[\"2025-01-06\"]},{\"name\":\"FNOL_COMPLETION_DATE\",\"sample_values\":[\"2025-01-06\"]},{\"name\":\"LOSS_DATE\",\"sample_values\":[\"2025-01-06\"]},{\"name\":\"REPORTED_DATE\",\"sample_values\":[\"2025-01-06\"]}]},{\"name\":\"CLAIM_LINES\",\"dimensions\":[{\"name\":\"CLAIM_NO\",\"sample_values\":[\"1899\"]},{\"name\":\"CLAIM_STATUS\",\"sample_values\":[\"Open\"]},{\"name\":\"CLAIMANT_ID\",\"sample_values\":[\"19\"]},{\"name\":\"LINE_NO\",\"sample_values\":[\"17\",\"18\",\"16\"]},{\"name\":\"LOSS_DESCRIPTION\",\"sample_values\":[\"Damaged Dwelling\",\"Damaged Fence\",\"Damaged Lawn\"]},{\"name\":\"PERFORMER_ID\",\"sample_values\":[\"181\",\"171\",\"191\"]}],\"time_dimensions\":[{\"name\":\"CREATED_DATE\",\"sample_values\":[\"2025-01-06\"]},{\"name\":\"REPORTED_DATE\",\"sample_values\":[\"2025-01-06\"]}]},{\"name\":\"FINANCIAL_TRANSACTIONS\",\"dimensions\":[{\"name\":\"CURRENCY\",\"sample_values\":[\"USD\"]},{\"name\":\"FINANCIAL_TYPE\",\"sample_values\":[\"RSV\",\"PAY\"]},{\"name\":\"FXID\",\"sample_values\":[\"22\",\"23\",\"24\"]},{\"name\":\"LINE_NO\",\"sample_values\":[\"17\",\"18\",\"16\"]}],\"facts\":[{\"name\":\"FIN_TX_AMT\",\"sample_values\":[\"3000.00\",\"3500.00\",\"4000.00\"]}],\"time_dimensions\":[{\"name\":\"FIN_TX_POST_DT\",\"sample_values\":[\"2025-03-06\",\"2025-06-15\",\"2025-02-15\"]}]},{\"name\":\"INVOICES\",\"dimensions\":[{\"name\":\"CURRENCY\",\"sample_values\":[\"USD\"]},{\"name\":\"DESCRIPTION\",\"sample_values\":[\"Hardware\",\"Labor\",\"Wooden Logs\"]},{\"name\":\"INV_ID\",\"sample_values\":[\"7\",\"5\",\"6\"]},{\"name\":\"INV_LINE_NBR\",\"sample_values\":[\"3\",\"2\",\"1\"]},{\"name\":\"LINE_NO\",\"sample_values\":[\"16\",\"18\",\"17\"]},{\"name\":\"VENDOR\",\"sample_values\":[\"LMN\",\"XYZ\",\"ABC\"]}],\"facts\":[{\"name\":\"INVOICE_AMOUNT\",\"sample_values\":[\"2500.00\",\"1000.00\",\"500.00\"]}],\"time_dimensions\":[{\"name\":\"INVOICE_DATE\",\"sample_values\":[\"2025-05-15\",\"2025-03-18\",\"2025-04-20\"]}]}],\"relationships\":[{\"name\":\"CLAIM_LINES_TO_AUTHORIZATION\"},{\"name\":\"CLAIM_TO_CLAIM_LINES_CLAIM_ID\"},{\"name\":\"FINANCIAL_TO_CLAIM_LINES\"},{\"name\":\"CLAIM_LINES_TO_INVOICE\"},{\"name\":\"FINANCIAL_TO_INVOICE\"}],\"verified_queries\":[{\"name\":\"Was a payment made in excess of the performer authority? Please respond yes or no and provide more details if yes.\",\"question\":\"Was a payment made in excess of the performer authority? Please respond yes or no and provide more details if yes.\",\"sql\":\"WITH auth_fin_tx AS (\\\\n  SELECT\\\\n    a.performer_id,\\\\n    a.to_amt AS max_authorized_amt,\\\\n    ft.fin_tx_amt\\\\n  FROM\\\\n    authorization AS a\\\\n    INNER JOIN claim_lines AS cl ON a.performer_id = cl.performer_id\\\\n    INNER JOIN financial_transactions AS ft ON cl.line_no = ft.line_no\\\\n)\\\\nSELECT\\\\n  performer_id,\\\\n  max_authorized_amt,\\\\n  fin_tx_amt,\\\\n  CASE\\\\n    WHEN fin_tx_amt > max_authorized_amt THEN ''Yes''\\\\n    ELSE ''No''\\\\n  END AS payment_exceeds_authority\\\\nFROM\\\\n  auth_fin_tx\",\"use_as_onboarding_question\":false,\"verified_by\":\"Marie Duran\",\"verified_at\":1755720163},{\"name\":\"Was a payment issued to the vendor 30+ calendar days after the invoice was received? If yes, please provide details\",\"question\":\"Was a payment issued to the vendor 30+ calendar days after the invoice was received? If yes, please provide details\",\"sql\":\"WITH invoice_payment AS (\\\\n  SELECT\\\\n    i.vendor,\\\\n    i.invoice_date,\\\\n    ft.fin_tx_post_dt,\\\\n    DATEDIFF(DAY, i.invoice_date, ft.fin_tx_post_dt) AS days_between\\\\n  FROM\\\\n    invoices AS i\\\\n    LEFT OUTER JOIN financial_transactions AS ft ON i.line_no = ft.line_no\\\\n)\\\\nSELECT\\\\n  vendor,\\\\n  invoice_date,\\\\n  fin_tx_post_dt,\\\\n  days_between,\\\\n  CASE\\\\n    WHEN days_between > 30 THEN ''Yes''\\\\n    ELSE ''No''\\\\n  END AS payment_issued_late\\\\nFROM\\\\n  invoice_payment\",\"use_as_onboarding_question\":false,\"verified_by\":\"Marie Duran\",\"verified_at\":1755720298},{\"name\":\"Was a payment issued to the vendor 8-13 calendar days after the invoice was received?\",\"question\":\"Was a payment issued to the vendor 8-13 calendar days after the invoice was received?\",\"sql\":\"WITH invoice_payment AS (\\\\n  SELECT\\\\n    i.vendor,\\\\n    i.invoice_date,\\\\n    ft.fin_tx_post_dt,\\\\n    DATEDIFF(DAY, i.invoice_date, ft.fin_tx_post_dt) AS days_between\\\\n  FROM\\\\n    invoices AS i\\\\n    LEFT OUTER JOIN financial_transactions AS ft ON i.line_no = ft.line_no\\\\n)\\\\nSELECT\\\\n  vendor,\\\\n  invoice_date,\\\\n  fin_tx_post_dt,\\\\n  days_between,\\\\n  CASE\\\\n    WHEN days_between BETWEEN 8\\\\n    AND 13 THEN ''Yes''\\\\n    ELSE ''No''\\\\n  END AS payment_issued_within_range\\\\nFROM\\\\n  invoice_payment\",\"use_as_onboarding_question\":false,\"verified_by\":\"Marie Duran\",\"verified_at\":1755720353}]}');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Optional - Create a Semantic View from the Snowsight UI (Cortex Analyst)\n",
    "\n",
    "You can also create the `CA_INSURANCE_CLAIMS_DEMO` semantic view directly from the Snowsight UI using **Cortex Analyst**, instead of only using SQL. The steps below describe how to build a semantic view equivalent to the one defined by the SQL script in section **4.1**.\n",
    "\n",
    "1. **Open Cortex Analyst in Snowsight**\n",
    "   - In the left-hand navigation menu, select **AI & ML** » **Analyst**.\n",
    "\n",
    "2. **Start a new semantic view**\n",
    "   - In the top menu bar, select **Create new** » **Create new Semantic View**.\n",
    "\n",
    "3. **Choose where to store the semantic view**\n",
    "   - Select the **Database** and **Schema** where you want to store the view (for this lab, use `INSURANCE_CLAIMS_DEMO` / `LOSS_CLAIMS`).\n",
    "   - Enter a **Name** such as `TEST_CA_INSURANCE_CLAIMS_DEMO` and an optional description, then select **Next**.\n",
    "\n",
    "4. **(Optional) Provide business context**\n",
    "   - Add example **business questions** and (optionally) their corresponding **SQL queries** to help the AI model better understand your intent.\n",
    "   - You can use the questions and SQL patterns from the `CA_INSURANCE_CLAIMS_DEMO` definition in section **4.1** as inspiration.\n",
    "\n",
    "5. **Select source tables or views**\n",
    "   - In the **Select tables** step, choose the core claims tables you want to include (for example `CLAIMS`, `CLAIM_LINES`, `FINANCIAL_TRANSACTIONS`, `AUTHORIZATION`, and `INVOICES`).\n",
    "   - Select **Next**.\n",
    "\n",
    "6. **Select columns and optional enhancements**\n",
    "   - In the **Select columns** step, choose the specific columns you want exposed in the semantic view.\n",
    "   - Optionally, enable the checkboxes to:\n",
    "     - Add **sample values** for key columns.\n",
    "     - Generate **AI descriptions** for tables and columns.\n",
    "   - These options help improve the accuracy and explainability of AI-generated queries.\n",
    "\n",
    "7. **Create and Save**\n",
    "   - Select **Create** to save the semantic view.\n",
    "\n",
    "Once created, this UI-defined semantic view will be functionally equivalent to the `CA_INSURANCE_CLAIMS_DEMO` semantic view created by the SQL script in section **4.1** below, and it can be used by Cortex Analyst and your Insurance Claims Agent.\n",

    "To mirror the exact **relationships** defined in the SQL semantic view, you can manually edit the semantic view in Snowsight:\n" ,
    "\n",

    "8. **Edit relationships in the semantic view editor**\n",
    "    - Open the semantic view you just created in **Cortex Analyst** and switch to the **Relationships** section.\n",
     "   - Select **+ Relationship** (or the **+** icon next to *Relationships*).\n",
    "    - In the form that appears:\n",
     "     - Enter the **relationship name**.\n",
     "     - Select the two **tables** involved in the relationship.\n",
     "     - Choose the **join columns** from each table (foreign key and primary key/unique column).\n",
     "     - Select **Add** to save that relationship.\n",
      "  - Repeat these steps to add the following relationships so they match the SQL definition in section **4.1**:\n",
     "     - **`CLAIM_LINES_TO_AUTHORIZATION`**: `CLAIM_LINES(PERFORMER_ID)` references `AUTHORIZATION(PERFORMER_ID)`.\n",
     "     - **`CLAIM_TO_CLAIM_LINES_CLAIM_ID`**: `CLAIM_LINES(CLAIM_NO)` references `CLAIMS(CLAIM_NO)`.\n",
      "    - **`FINANCIAL_TO_CLAIM_LINES`**: `CLAIM_LINES(LINE_NO)` references `FINANCIAL_TRANSACTIONS(LINE_NO)`.\n",
      "    - **`CLAIM_LINES_TO_INVOICE`**: `INVOICES(LINE_NO)` references `CLAIM_LINES(LINE_NO)`.\n",
       "   - **`FINANCIAL_TO_INVOICE`**: `INVOICES(LINE_NO)` references `FINANCIAL_TRANSACTIONS(LINE_NO)`.\n",
       " - When all relationships have been added, select **Save** on the semantic view. The Relationships section in the UI will now match the SQL `RELATIONSHIPS` block used in section **4.1**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000035",
   "metadata": {
    "name": "cell36"
   },
   "source": [
    "## 5. Create the Insurance Claims Agent (Snowflake Intelligence)\n",
    "\n",
    "In this section you will:\n",
    "- Create a **Snowflake Intelligence Agent** `CLAIMS_AUDIT_AGENT`.\n",
    "- Wire it to **Cortex Analyst** (semantic SQL), **Cortex Search** (documents), and the helper functions/procedures you created.\n",
    "- Provide **instructions and sample questions** that guide the agent’s behavior for claims auditing.\n",
    "\n",
    "### What is a Snowflake Intelligence Agent?\n",
    "- A **Snowflake Intelligence Agent** is a **serverless orchestration layer** that:\n",
    "  - Accepts **natural language questions** from users (via Snowsight, API, or applications).\n",
    "  - Uses one or more **tools** (Cortex Analyst, Cortex Search, SQL functions/procedures) to gather evidence.\n",
    "  - Synthesizes and returns an **explanatory answer**, optionally with charts and drill‑downs.\n",
    "- The **agent specification JSON** in this lab defines:\n",
    "  - **Instructions** (persona, priorities, what “complete claim” means).\n",
    "  - **Sample questions** (onboarding prompts to test the agent).\n",
    "  - **Tools and tool_resources** pointing to your semantic view, search services, and helper functions.\n",
    "\n",
    "For more details, see the Snowflake documentation at `https://docs.snowflake.com` and search for **\"Snowflake Intelligence\"** and **\"Agent specification\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000036",
   "metadata": {
    "language": "sql",
    "name": "cell37",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 5.1 Create the CLAIMS_AUDIT_AGENT Snowflake Intelligence Agent\n",
    "CREATE OR REPLACE AGENT INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.CLAIMS_AUDIT_AGENT\n",
    "WITH PROFILE='{ \"display_name\": \"Insurance Claims Agent\" }'\n",
    "  COMMENT=$$ This agent analyzes insurance claims by combining structured data queries (Cortex Analyst) with unstructured document search (Cortex Search for guidelines and claim notes). It can audit claims for compliance, verify payments against authorization limits, transcribe call recordings, summarize evidence images, classify documents, and assess claim completeness. $$\n",
    "FROM SPECIFICATION\n",
    "$$\n",
    "{\n",
    "    \"models\": {\n",
    "      \"orchestration\": \"auto\"\n",
    "    },\n",
    "    \"instructions\": {\n",
    "      \"response\": \"In your response, address me by my first name\",\n",
    "      \"orchestration\": \"You are an insurance claims agent.\\n\\nPriority 1 (Analysis):\\nUse CA_INS (Cortex Analyst with semantic view) for quantitative questions about the claim.\\n\\nUse the two Cortex Search tools (claim_notes, guidelines) for guidelines, notes, or qualitative \\\"why\\\" questions.\\n\\n-If the user asks about claim completeness, deem a claim as complete if the following are available: Claim level data, claim lines, financial, claim notes.\\n\\n-Produce charts when possible.\",\n",
    "      \"sample_questions\": [\n",
    "        {\n",
    "          \"question\": \"Based on the state of new jersey's insurance claims guidelines, have any of my claims been outside of the mandated settlement window?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Was there a reserve rationale in the file notes?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Was a payment made in excess of the reserve amount for claim 1899?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Can you transcribe the media file 'ins_co_1899_call.wav' stored in '@INSURANCE_CLAIMS_DEMO.loss_claims.loss_evidence'?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"What is the callers intent?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"What is the customers reason for calling?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Can you give me a summary of 1899_claim_evidence1.jpeg image please?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"What is the similarity score between the summary of the claim evidence and the claim description for claim 1899?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Does the file Gemini_Generated3.jpeg appear to be tampered with?\"\n",
    "        },\n",
    "        {\n",
    "          \"question\": \"Is claim 1899 complete?\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    \"tools\": [\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"cortex_analyst_text_to_sql\",\n",
    "          \"name\": \"TEXT2SQL\",\n",
    "          \"description\": \"AUTHORIZATION:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table manages authorization limits for performers/providers in the insurance claims system. It defines spending authority ranges with minimum and maximum amounts that can be authorized by specific performers.\\n- The table establishes financial controls by setting authorization boundaries, ensuring that claim payments stay within approved limits for each performer.\\n- LIST OF COLUMNS: PERFORMER_ID (unique identifier for performer - links to PERFORMER_ID in CLAIM_LINES), CURRENCY (transaction currency), FROM_AMT (minimum authorization amount), TO_AMT (maximum authorization amount)\\n\\nCLAIMS:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This is the main claims table containing comprehensive information about insurance claims including policy details, loss information, and claim status. It serves as the central hub for claim management with details about when losses occurred, were reported, and processed.\\n- The table tracks the complete lifecycle of claims from initial loss occurrence through reporting and processing, providing essential data for claim analysis and management.\\n- LIST OF COLUMNS: CLAIM_NO (unique claim identifier), LINE_OF_BUSINESS (business type), CLAIM_STATUS (current claim state), CAUSE_OF_LOSS (loss reason), CLAIMANT_ID (person submitting claim), PERFORMER (service provider - links to PERFORMER_ID in other tables), POLICY_NO (insurance policy identifier), LOSS_DESCRIPTION (damage details), LOSS_STATE (loss location state), LOSS_ZIP_CODE (loss location zip), CREATED_DATE (claim creation date), LOSS_DATE (when loss occurred), REPORTED_DATE (when claim was reported), FNOL_COMPLETION_DATE (first notice of loss completion)\\n\\nCLAIM_LINES:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table contains individual line items for each claim, breaking down claims into specific components or damages. Each line represents a separate aspect of the overall claim with its own status and performer assignment.\\n- The table enables detailed tracking of claim components, allowing for granular management of different types of damages or services within a single claim.\\n- LIST OF COLUMNS: CLAIM_NO (links to CLAIM_NO in CLAIMS), LOSS_DESCRIPTION (specific line item damage), CLAIM_STATUS (line item status), CLAIMANT_ID (claim submitter), PERFORMER_ID (assigned service provider - links to AUTHORIZATION), LINE_NO (unique line identifier - links to FINANCIAL_TRANSACTIONS and INVOICES), CREATED_DATE (line creation date), REPORTED_DATE (line reporting date)\\n\\nFINANCIAL_TRANSACTIONS:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table records all financial activities related to claims including payments and reserves. It tracks the monetary flow for each claim line item with transaction types, amounts, and posting dates.\\n- The table provides complete financial audit trail for claims processing, enabling tracking of reserves set aside and actual payments made for claim resolution.\\n- LIST OF COLUMNS: FXID (foreign exchange transaction ID), FINANCIAL_TYPE (transaction category like RSV/PAY), CURRENCY (transaction currency), LINE_NO (links to CLAIM_LINES and INVOICES), FIN_TX_POST_DT (transaction posting date), FIN_TX_AMT (transaction amount)\\n\\nINVOICES:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table contains invoice information from vendors providing services or materials for claim repairs. It includes detailed line items with descriptions, amounts, and vendor information for tracking claim-related expenses.\\n- The table facilitates vendor payment processing and expense tracking by maintaining detailed records of all invoiced items and their associated costs.\\n- LIST OF COLUMNS: INV_ID (invoice identifier), INV_LINE_NBR (invoice line number), LINE_NO (links to CLAIM_LINES and FINANCIAL_TRANSACTIONS), DESCRIPTION (item/service description), CURRENCY (invoice currency), VENDOR (supplier name), INVOICE_DATE (invoice issue date), INVOICE_AMOUNT (invoice total)\\n\\nGUIDELINES_CHUNK_TABLE:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table stores processed guidelines documents in chunks for easy retrieval and reference. It contains insurance claims processing guidelines broken into manageable text segments.\\n- The table supports compliance and procedural guidance by providing searchable access to regulatory and company guidelines for claims handling.\\n- LIST OF COLUMNS: FILENAME (guideline document name), FILE_URL (document storage location), CHUNK (guideline text segment), LANGUAGE (content language)\\n\\nNOTES_CHUNK_TABLE:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table contains claim-specific notes and documentation broken into text chunks for analysis and retrieval. It stores detailed notes about claim progress, decisions, and observations.\\n- The table provides comprehensive claim documentation history, enabling detailed tracking of claim handling decisions and progress updates.\\n- LIST OF COLUMNS: FILENAME (notes document name), FILE_URL (document storage location), CHUNK (notes text segment), LANGUAGE (content language), CLAIM_NO (links to CLAIMS table)\\n\\nPARSED_INVOICES:\\n- Database: INSURANCE_CLAIMS_DEMO, Schema: LOSS_CLAIMS\\n- This table contains extracted content from invoice images or documents that have been processed through parsing technology. It stores the raw extracted text from invoice files for further processing.\\n- The table enables automated invoice processing by capturing and storing parsed invoice content for integration with the structured invoice data.\\n- LIST OF COLUMNS: FILENAME (source invoice file), EXTRACTED_CONTENT (parsed invoice text), PARSE_DATE (when parsing occurred)\\n\\nREASONING:\\nThis semantic model represents a comprehensive insurance claims management system that tracks the complete lifecycle of property insurance claims from initial loss through financial settlement. The model centers around claims and their associated line items, with strong relationships connecting authorization limits, financial transactions, invoices, and supporting documentation. The system enforces financial controls through performer authorization limits while maintaining detailed audit trails of all financial activities and supporting documentation.\\n\\nDESCRIPTION:\\nThe CA_INSURANCE_CLAIMS_DEMO semantic model is a comprehensive insurance claims management system from the INSURANCE_CLAIMS_DEMO database's LOSS_CLAIMS schema that tracks property insurance claims from loss occurrence through financial settlement. The model centers on the CLAIMS table which connects to CLAIM_LINES for detailed damage breakdowns, with each line item linked to FINANCIAL_TRANSACTIONS for payment tracking and INVOICES for vendor billing. The system includes financial controls through the AUTHORIZATION table that sets spending limits for performers, while NOTES_CHUNK_TABLE and GUIDELINES_CHUNK_TABLE provide supporting documentation and regulatory guidance. The PARSED_INVOICES table enables automated processing of invoice documents, creating a complete end-to-end claims processing workflow with full audit trails and compliance tracking.\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"cortex_search\",\n",
    "          \"name\": \"SEARCH_GUIDELINES\",\n",
    "          \"description\": \"\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"cortex_search\",\n",
    "          \"name\": \"SEARCH_CLAIM_NOTES\",\n",
    "          \"description\": \"\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"generic\",\n",
    "          \"name\": \"CLASSIFY_FUNCTION\",\n",
    "          \"description\": \"PROCEDURE/FUNCTION DETAILS:\\n- Type: Custom Function\\n- Language: SQL\\n- Signature: (FILE_NAME VARCHAR, STAGE_NAME VARCHAR)\\n- Returns: OBJECT\\n- Execution: Caller context with standard null handling\\n- Volatility: Volatile (uses AI processing and current timestamp)\\n- Primary Function: AI-powered document classification and analysis\\n- Target: Files stored in Snowflake stages\\n- Error Handling: Returns structured object with success indicators\\n\\nDESCRIPTION:\\nThis AI-powered document classification function analyzes files stored in Snowflake stages to automatically identify and categorize document types such as invoices, medical bills, insurance claims, policy documents, and other business-critical documents. The function leverages Snowflake's AI_EXTRACT capability to perform intelligent document analysis, returning a comprehensive JSON object that includes the classification type, detailed description, business context, document purpose, and a confidence score averaged across multiple AI analysis dimensions. Users should ensure they have appropriate permissions to access the specified stage and file, as the function requires read access to stage data and AI processing capabilities enabled in their Snowflake environment. The function is particularly valuable for organizations processing large volumes of mixed document types, as it provides consistent, automated classification with detailed metadata that can drive downstream business processes. The returned object structure makes it easy to integrate with data pipelines, reporting systems, and workflow automation tools while maintaining full traceability through timestamp tracking and complete classification data preservation.\\n\\nUSAGE SCENARIOS:\\n- Document intake processing: Automatically classify incoming documents from various sources (email attachments, file uploads, scanned documents) to route them to appropriate business processes and departments\\n- Insurance claims processing: Analyze uploaded claim documents, evidence images, and supporting materials to streamline claim review workflows and ensure proper categorization for regulatory compliance\\n- Financial document management: Classify invoices, receipts, financial statements, and correspondence to support automated accounting processes, audit trails, and regulatory reporting requirements\"\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"generic\",\n",
    "          \"name\": \"Parse_document\",\n",
    "          \"description\": \"PROCEDURE/FUNCTION DETAILS:\\n- Type: Custom Function\\n- Language: SQL\\n- Signature: (FILE_NAME VARCHAR)\\n- Returns: VARIANT\\n- Execution: Caller context with standard null handling\\n- Volatility: Stable (depends on file content)\\n- Primary Function: Document parsing and content extraction\\n- Target: Files stored in the loss_evidence stage within the INSURANCE_CLAIMS_DEMO.loss_claims schema\\n- Error Handling: Relies on Snowflake's AI_PARSE_DOCUMENT built-in error handling\\n\\nDESCRIPTION:\\nThis custom SQL function serves as a specialized document processing tool designed specifically for insurance loss claims operations, leveraging Snowflake's AI-powered document parsing capabilities to extract structured data from evidence files. The function takes a file name as input and automatically retrieves the corresponding document from the designated loss_evidence file stage, then processes it using advanced layout analysis with page-splitting enabled to maintain document structure integrity. This function is particularly valuable for insurance companies and claims processors who need to systematically extract information from various types of loss evidence documents such as police reports, medical records, repair estimates, or photographic evidence submitted as part of insurance claims. The function returns data in VARIANT format, providing flexibility to handle diverse document types and extracted content structures, making it ideal for downstream processing workflows that require structured data analysis. Users should ensure they have appropriate access permissions to both the file stage and the AI_PARSE_DOCUMENT functionality, and should be prepared to handle potential parsing errors for corrupted or unsupported file formats.\\n\\nUSAGE SCENARIOS:\\n- Claims Processing Automation: Automatically extract key information from newly submitted claim evidence documents to populate claim databases and accelerate adjuster review processes\\n- Bulk Document Analysis: Process large volumes of historical claim documents to extract patterns, identify fraud indicators, or perform compliance audits across the insurance portfolio\\n- Integration Testing: Validate document parsing workflows in development environments by testing various document formats and structures before deploying to production claim processing systems\",\n",
    "          \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"file_name\": {\n",
    "                \"type\": \"string\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"file_name\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"generic\",\n",
    "          \"name\": \"Image_summary\",\n",
    "          \"description\": \"PROCEDURE/FUNCTION DETAILS:\\n- Type: Custom Function\\n- Language: SQL\\n- Signature: (IMAGE_FILE VARCHAR, STAGE_NAME VARCHAR)\\n- Returns: VARCHAR\\n- Execution: Caller context with standard null handling\\n- Volatility: Volatile (depends on external AI service)\\n- Primary Function: AI-powered image analysis and summarization\\n- Target: Image files stored in Snowflake stages\\n- Error Handling: Relies on Snowflake Cortex error handling\\n\\nDESCRIPTION:\\nThis custom function leverages Snowflake's Cortex AI capabilities to automatically analyze and summarize images stored in your data warehouse stages. The function takes an image file name and stage location as inputs, then uses Claude-3.5-Sonnet AI model to generate concise 100-word summaries of key insights found in the image. This is particularly valuable for organizations dealing with large volumes of visual data such as charts, diagrams, documents, or photographs that need to be catalogued and understood at scale. Users must have appropriate permissions to access both the specified stage and Snowflake Cortex services, and should be aware that processing costs will apply for each AI model invocation. The function returns a text summary that can be stored, indexed, or used for further analysis workflows.\\n\\nUSAGE SCENARIOS:\\n- Business Intelligence: Automatically summarize chart images, dashboard screenshots, or report visualizations to create searchable metadata and improve data discovery across your organization\\n- Document Processing: Extract key insights from scanned documents, forms, or technical diagrams stored in your data lake to enable automated content classification and retrieval\\n- Quality Assurance: Analyze product images, inspection photos, or monitoring screenshots to generate standardized descriptions for compliance reporting and audit trails\",\n",
    "          \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"image_file\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"stage_name\": {\n",
    "                \"description\": \"default the stage to INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE\",\n",
    "                \"type\": \"string\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"image_file\",\n",
    "              \"stage_name\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"generic\",\n",
    "          \"name\": \"TRANSCRIBE_CALLS\",\n",
    "          \"description\": \"PROCEDURE/FUNCTION DETAILS:\\n- Type: Custom Function\\n- Language: SQL\\n- Signature: (FILE_NAME VARCHAR, STAGE_NAME VARCHAR)\\n- Returns: OBJECT\\n- Execution: OWNER with exception handling\\n- Volatility: Stable\\n- Primary Function: Audio/Video File Transcription\\n- Target: Media files stored in Snowflake stages\\n- Error Handling: Comprehensive try-catch with structured error responses\\n\\nDESCRIPTION:\\nThis custom function provides automated transcription capabilities for audio and video files stored in Snowflake stages, leveraging Snowflake's AI_TRANSCRIBE functionality with speaker-level timestamp granularity. The function takes a file name and stage name as parameters, processes the media file through Snowflake's AI transcription service, and returns a structured JSON object containing either the successful transcription results or detailed error information. It executes with OWNER privileges to ensure proper access to stage files and AI services, while implementing robust error handling that captures SQL error codes and messages for troubleshooting. The function is designed for business users who need to convert speech content from recorded meetings, interviews, or other audio/video materials into searchable text format. Users should ensure they have appropriate permissions to access the specified stage and that the target files are in supported audio/video formats, as the function will return detailed error information if transcription fails due to file format issues, permission problems, or AI service limitations.\\n\\nUSAGE SCENARIOS:\\n- Meeting transcription: Convert recorded business meetings, conference calls, or interviews stored in Snowflake stages into searchable text with speaker identification and timestamps\\n- Content analysis workflows: Process large volumes of audio/video content for compliance monitoring, sentiment analysis, or content categorization in data pipeline operations\\n- Development and testing: Validate transcription accuracy and error handling behavior when building applications that integrate speech-to-text functionality with Snowflake's AI capabilities\",\n",
    "          \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"file_name\": {\n",
    "                \"type\": \"string\"\n",
    "              },\n",
    "              \"stage_name\": {\n",
    "                \"description\": \"default the stage to INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE\",\n",
    "                \"type\": \"string\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"file_name\",\n",
    "              \"stage_name\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      {\n",
    "        \"tool_spec\": {\n",
    "          \"type\": \"generic\",\n",
    "          \"name\": \"REDACT_EMAIL\",\n",
    "          \"description\": \"PROCEDURE/FUNCTION DETAILS:\\n- Type: Table Function\\n- Language: SQL\\n- Signature: (CLAIM_NO_PARAM VARCHAR)\\n- Returns: TABLE with claim details including original and AI-redacted email content\\n- Execution: OWNER privileges with standard null handling\\n- Volatility: Stable (consistent results for same inputs)\\n- Primary Function: Email content retrieval and PII redaction using Snowflake Cortex AI\\n- Target: CUSTOMER_CLAIM_EMAILS table records filtered by claim number\\n- Error Handling: Standard SQL exception handling with resultset validation\\n\\nDESCRIPTION:\\nThis table function retrieves customer claim email records for a specific claim number and automatically redacts personally identifiable information (PII) from email content using Snowflake's Cortex AI_REDACT functionality. The function returns both the original email body and a redacted version where sensitive information like names, addresses, phone numbers, and other PII types are automatically detected and masked. This is particularly valuable for compliance teams, customer service representatives, and data analysts who need to review claim correspondence while maintaining privacy standards and regulatory compliance. The function executes with owner privileges to ensure consistent access to the underlying email data, and results are ordered by received date in descending order to show the most recent communications first. Users should ensure they have appropriate permissions to access claim data and understand that the AI redaction process may occasionally miss context-specific sensitive information that requires manual review.\\n\\nUSAGE SCENARIOS:\\n- Compliance audits: Generate redacted email trails for regulatory reviews while protecting customer privacy and meeting data protection requirements\\n- Customer service training: Provide sanitized real-world email examples for staff training without exposing actual customer personal information\\n- Data analysis and reporting: Enable analysts to study communication patterns and content themes in claim emails without accessing sensitive personal details\",\n",
    "          \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "              \"claim_no_param\": {\n",
    "                \"type\": \"string\"\n",
    "              }\n",
    "            },\n",
    "            \"required\": [\n",
    "              \"claim_no_param\"\n",
    "            ]\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    ],\n",
    "    \"tool_resources\": {\n",
    "      \"CLASSIFY_FUNCTION\": {\n",
    "        \"execution_environment\": {\n",
    "          \"query_timeout\": 30,\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"identifier\": \"INSURANCE_CLAIMS_DEMO_DB.ANALYTICS.CLASSIFY_DOCUMENT\",\n",
    "        \"name\": \"CLASSIFY_DOCUMENT(VARCHAR, DEFAULT VARCHAR)\",\n",
    "        \"type\": \"function\"\n",
    "      },\n",
    "      \"Image_summary\": {\n",
    "        \"execution_environment\": {\n",
    "          \"query_timeout\": 60,\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"identifier\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.GET_IMAGE_SUMMARY\",\n",
    "        \"name\": \"GET_IMAGE_SUMMARY(VARCHAR, VARCHAR)\",\n",
    "        \"type\": \"function\"\n",
    "      },\n",
    "      \"Parse_document\": {\n",
    "        \"execution_environment\": {\n",
    "          \"query_timeout\": 30,\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"identifier\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.PARSE_DOCUMENT_FROM_STAGE\",\n",
    "        \"name\": \"PARSE_DOCUMENT_FROM_STAGE(VARCHAR)\",\n",
    "        \"type\": \"function\"\n",
    "      },\n",
    "      \"REDACT_EMAIL\": {\n",
    "        \"execution_environment\": {\n",
    "          \"query_timeout\": 180,\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"identifier\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.REDACT_CLAIM_EMAIL_PII\",\n",
    "        \"name\": \"REDACT_CLAIM_EMAIL_PII(VARCHAR)\",\n",
    "        \"type\": \"procedure\"\n",
    "      },\n",
    "      \"SEARCH_CLAIM_NOTES\": {\n",
    "        \"max_results\": 4,\n",
    "        \"search_service\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.INSURANCE_CLAIMS_DEMO_CLAIM_NOTES\",\n",
    "        \"id_column\": \"file_url\",\n",
    "        \"title_column\": \"filename\"\n",
    "      },\n",
    "      \"SEARCH_GUIDELINES\": {\n",
    "        \"max_results\": 4,\n",
    "        \"search_service\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.INSURANCE_CLAIMS_DEMO_GUIDELINES\",\n",
    "        \"id_column\": \"file_url\",\n",
    "        \"title_column\": \"filename\"\n",
    "      },\n",
    "      \"TEXT2SQL\": {\n",
    "        \"execution_environment\": {\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"semantic_model_file\": \"@INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.LOSS_EVIDENCE/loss_claims.yaml\"\n",
    "      },\n",
    "      \"TRANSCRIBE_CALLS\": {\n",
    "        \"execution_environment\": {\n",
    "          \"query_timeout\": 60,\n",
    "          \"type\": \"warehouse\",\n",
    "          \"warehouse\": \"CLAIMS_AGENT_WH\"\n",
    "        },\n",
    "        \"identifier\": \"INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.TRANSCRIBE_AUDIO_SIMPLE\",\n",
    "        \"name\": \"TRANSCRIBE_AUDIO_SIMPLE(VARCHAR, DEFAULT VARCHAR)\",\n",
    "        \"type\": \"procedure\"\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "$$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Optional - Create the Insurance Claims Agent from the Snowsight UI\n",
    "\n",
    "You can also create the `CLAIMS_AUDIT_AGENT` directly from the Snowsight UI, instead of only using the SQL script in section **5.1**. The steps below describe how to build an equivalent Cortex Agent using the **Agents** interface.\n",
    "\n",
    "1. **Open AI & ML Studio**\n",
    "   - Navigate to **AI & ML** in the primary Snowsight navigation menu.\n",
    "   - Select **Agents** to open **Cortex Agents**.\n",
    "\n",

    "2. **Create a new agent**\n",
    "   - In the top right corner, click **+ Create agent**.\n",
    "   - Fill in the basic details:\n",
    "     - Select the **Database** and **Schema** where you want to store the view (for this lab, use `INSURANCE_CLAIMS_DEMO` / `LOSS_CLAIMS`).\n",
    "     - **Agent object name**: A unique identifier for the agent object in Snowflake (for example `TEST_CLAIMS_AUDIT_AGENT`).\n",
    "     - **Display name**: A friendly name users will see in the chat UI (for example **\"TEST Insurance Claims Agent\"**).\n",
    "     - Click **Create agent**.\n",
    "     - (Optional) In the **About** section, add a **description** and **sample questions** similar to those used in the SQL definition in section **5.1**. Ex - Was a payment made in excess of the reserve amount for claim 1899?\n",
    "\n",
    "3. **Configure tools and capabilities**\n",
    "   - Navigate to the **Tools** section to add capabilities:\n",
    "     - **Cortex Analyst**: Enable this so the agent can query structured data using natural language. Add your semantic view (for example `CA_INSURANCE_CLAIMS_DEMO`).\n",
               "     - Select the **Database** and **Schema** where you want to store the view (for this lab, use `INSURANCE_CLAIMS_DEMO` / `LOSS_CLAIMS`).\n",
               "     - **Semantic View name**: Select CA_INSURANCE_CLAIMS_DEMO view from dropdown.\n",
               "     - **Name**: A friendly name users will see in the chat UI (for example **\"INSURANCE CLAIMS\"**).\n",
               "     - Click **Add**.\n",
    "     - **Cortex Search Services**: Add existing Cortex Search services such as `INSURANCE_CLAIMS_DEMO_claim_notes` and `INSURANCE_CLAIMS_DEMO_guidelines` so the agent can perform RAG over claim notes and guidelines.\n",
               "     - Select the **Database** and **Schema** where you want to store the search services (for this lab, use `INSURANCE_CLAIMS_DEMO` and `LOSS_CLAIMS`).\n",
               "     - **Search Service name**: Select INSURANCE_CLAIMS_DEMO_claim_notes service from dropdown.\n",
               "     - Select FILE_URL as ID column and FILENAME as Title Column. \n",
               "     - **Name**: A name users will see in the Agent definition (for example **\"INSURANCE_CLAIMS_NOTES\"**).\n",
               "     - Click **Add**.\n",
               "     - Repeat same process for INSURANCE_CLAIMS_DEMO_guidelines search service addition.\n",
    "     - **Custom Tools / Plugins**: Optionally add stored procedures and functions (for example classification, parsing, transcription, and redaction functions defined earlier in this lab) as custom tools for specialized operations.\n",
    "\n",
    "4. **Define orchestration and behavior**\n",
    "   - Go to the **Orchestration** (or **Instructions**) section.\n",
    "   - Provide natural-language **instructions** describing the agent’s persona and behavior, such as:\n",
    "     - How it should combine **Cortex Analyst** (for structured claims data) with **Cortex Search** (for notes and guidelines).\n",
    "     - How to determine whether a claim is **complete**.\n",
    "     - How to format responses (charts, explanations, references to source data), similar to the instructions embedded in the SQL agent definition.\n",
    "\n",
    "5. **Save and use the agent**\n",
    "   - Click **Save** to finalize the configuration.\n",
    "   - Your Cortex Agent is now ready for interaction within Snowsight’s **Snowflake Intelligence** chat interface and can behave equivalently to the `CLAIMS_AUDIT_AGENT` created via SQL in section **5.1**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce110000-1111-2222-3333-ffffff000039",
   "metadata": {
    "name": "cell40"
   },
   "source": [
    "## 6. Register and Validate the Agent in Snowflake Intelligence\n",
    "\n",
    "In this final section you will:\n",
    "- Create a helper procedure to (re)add the agent to the default **Snowflake Intelligence** object.\n",
    "- Call the procedure to register the agent so it appears in the Snowflake Intelligence UI.\n",
    "\n",
    "### How Snowflake Intelligence uses the agent\n",
    "- **Snowflake Intelligence** is the **entry point UI and API** for interacting with agents.\n",
    "- When you add `CLAIMS_AUDIT_AGENT` to the default Intelligence object:\n",
    "  - It becomes available as a **named assistant** inside Snowsight (and via APIs).\n",
    "  - Users can ask questions like *“Was a payment made in excess of the performer authority?”* and the platform will:\n",
    "    - Route the question to the `CLAIMS_AUDIT_AGENT`.\n",
    "    - Let the agent call Cortex Analyst, Cortex Search, and helper tools.\n",
    "    - Return a grounded, auditable answer.\n",
    "\n",
    "For more details, see `https://docs.snowflake.com` and search for **\"Snowflake Intelligence\"** and **\"adding agents\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce110000-1111-2222-3333-ffffff000040",
   "metadata": {
    "language": "sql",
    "name": "cell41",
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": [
    "-- 6.1 Add the CLAIMS_AUDIT_AGENT to the default Snowflake Intelligence object\n",
    "USE ROLE ACCOUNTADMIN;\n",
    "\n",
    "CREATE OR REPLACE PROCEDURE INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.ADD_AGENT_TO_INTELLIGENCE()\n",
    "RETURNS VARCHAR\n",
    "LANGUAGE SQL\n",
    "EXECUTE AS CALLER\n",
    "AS\n",
    "$$\n",
    "BEGIN\n",
    "    BEGIN\n",
    "        ALTER SNOWFLAKE INTELLIGENCE SNOWFLAKE_INTELLIGENCE_OBJECT_DEFAULT \n",
    "          DROP AGENT INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.CLAIMS_AUDIT_AGENT;\n",
    "    EXCEPTION\n",
    "        WHEN OTHER THEN\n",
    "            NULL;\n",
    "    END;\n",
    "    \n",
    "    ALTER SNOWFLAKE INTELLIGENCE SNOWFLAKE_INTELLIGENCE_OBJECT_DEFAULT \n",
    "      ADD AGENT INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.CLAIMS_AUDIT_AGENT;\n",
    "    \n",
    "    RETURN 'Agent added successfully to Snowflake Intelligence';\n",
    "END;\n",
    "$$;\n",
    "\n",
    "CALL INSURANCE_CLAIMS_DEMO.LOSS_CLAIMS.ADD_AGENT_TO_INTELLIGENCE();\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "lastEditStatus": {
   "authorEmail": "sarju.patel@snowflake.com",
   "authorId": "7264432159093",
   "authorName": "SAPATEL",
   "lastEditTime": 1767474461400,
   "notebookId": "wb534c3jii6oz2aisfxp",
   "sessionId": "7ba3a38b-a1e8-4b57-a4dc-d57949fd3a4d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
